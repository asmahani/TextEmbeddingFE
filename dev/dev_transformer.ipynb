{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b496b8e9-b46a-43be-bdbc-0dc15640e8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "dfEmbeddings = pd.read_csv(\n",
    "    'C:/Users/alire/OneDrive/data/statman_bitbucket/aki/LLM/March2024/openai_3large_operation.csv'\n",
    ")\n",
    "#dfEmbeddings.head()\n",
    "\n",
    "dfPatients = pd.read_csv(\n",
    "    'C:/Users/alire/OneDrive/data/statman_bitbucket/aki/LLM/March2024/patients_for_python.csv'\n",
    ")\n",
    "#dfPatients#.head()\n",
    "\n",
    "my_features = ['age', 'is_female', 'height_residual', 'bmi']\n",
    "\n",
    "dfPatients_subset = dfPatients.loc[:, ['project_id', 'operation_no', 'kdigo_stage'] + my_features].dropna()\n",
    "#dfPatients_subset#.head()\n",
    "\n",
    "dfCombined = pd.merge(\n",
    "    dfPatients_subset\n",
    "    , dfEmbeddings\n",
    "    , on = ['project_id', 'operation_no']\n",
    "    , how = 'inner'\n",
    ")\n",
    "#dfCombined.head()\n",
    "\n",
    "X, y, Z, Xall = (\n",
    "    dfCombined.iloc[:, (3 + len(my_features)):].to_numpy()\n",
    "    , dfCombined.iloc[:, 2].to_numpy(dtype = 'int')\n",
    "    , dfCombined.iloc[:, 3:(3 + len(my_features))].to_numpy()\n",
    "    , dfCombined.iloc[:, 3:]\n",
    ")\n",
    "#X_train, X_test, y_train, y_test, Z_train, Z_test = train_test_split(X, y, Z, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2e465d4-c08f-43ba-8f63-c3d232dbd2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin, RegressorMixin\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "import numpy as np\n",
    "from sklearn.utils.validation import check_X_y, check_array\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.model_selection import KFold\n",
    "import copy\n",
    "\n",
    "class TextToNumberBase(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, nx = None, ncv = 5):\n",
    "        self.nx = nx\n",
    "        self.ncv = ncv\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Implement fitting logic here, if needed\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Implement transformation logic here\n",
    "        X_transformed = X  # Example transformation\n",
    "        return X_transformed\n",
    "\n",
    "class TextToNumberClassifier(TextToNumberBase, ClassifierMixin):\n",
    "    def __init__(self, base_learner = KNeighborsClassifier(), nx = None, ncv = 5, logit = True, laplace = True, **kwargs):\n",
    "        super().__init__(nx = nx, ncv = ncv)\n",
    "        self.base_learner = base_learner\n",
    "        self.knn = KNeighborsClassifier(**kwargs)\n",
    "        self.logit = logit\n",
    "        self.laplace = laplace\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if not self.nx:\n",
    "            self.nx = X.shape[1]\n",
    "        \n",
    "        if self.nx > X.shape[1]:\n",
    "            raise ValueError('X has fewer columns than nx')\n",
    "        \n",
    "        X, y = check_X_y(X, y)\n",
    "        if type_of_target(y) != 'binary':\n",
    "            raise ValueError('Target type must be binary')\n",
    "        \n",
    "        # select subset of columns and renormalize\n",
    "        X = np.apply_along_axis(lambda x: x / np.sqrt(np.sum(x * x)), 1, X[:, :self.nx])\n",
    "        \n",
    "        # create folds\n",
    "        kf = KFold(n_splits = self.ncv, shuffle = True)\n",
    "        kf.get_n_splits(X)\n",
    "        self.kfolds = kf\n",
    "        \n",
    "        # train model within each fold\n",
    "        trained_models = []\n",
    "        insample_prediction_proba = np.empty(len(y), dtype = float)\n",
    "        for (train_index, test_index) in kf.split(X):\n",
    "            tmp_knn = copy.deepcopy(self.knn).fit(X[train_index, :], y[train_index])\n",
    "            \n",
    "            tmp_pred = tmp_knn.predict_proba(X[test_index, :])[:, 1]\n",
    "            if self.laplace:\n",
    "                tmp_pred = (tmp_pred * self.knn.n_neighbors + 1) / (self.knn.n_neighbors + 2)\n",
    "            if self.logit:\n",
    "                tmp_pred = np.log(tmp_pred / (1.0 - tmp_pred))\n",
    "            insample_prediction_proba[test_index] = tmp_pred\n",
    "            \n",
    "            trained_models.append(tmp_knn)\n",
    "\n",
    "        self.trained_models = trained_models\n",
    "        self.insample_prediction_proba = np.reshape(insample_prediction_proba, (insample_prediction_proba.size, 1))\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        self.fit(X, y)\n",
    "        return self.insample_prediction_proba\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = check_array(X)\n",
    "        \n",
    "        # select subset of columns and renormalize\n",
    "        X = np.apply_along_axis(lambda x: x / np.sqrt(np.sum(x * x)), 1, X[:, :self.nx])\n",
    "        \n",
    "        all_preds = np.empty((len(X), self.ncv), dtype = float)\n",
    "        for n in range(self.ncv):\n",
    "            tmp_pred = self.trained_models[n].predict_proba(X)[:, 1]\n",
    "            if self.laplace:\n",
    "                tmp_pred = (tmp_pred * self.knn.n_neighbors + 1) / (self.knn.n_neighbors + 2)\n",
    "            if self.logit:\n",
    "                tmp_pred = np.log(tmp_pred / (1.0 - tmp_pred))\n",
    "            all_preds[:, n] = tmp_pred\n",
    "        ret = np.mean(all_preds, axis = 1)\n",
    "        return np.reshape(ret, (ret.size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb72c304-9025-4d74-b619-d754170be844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Xall_train, Xall_test, y_train, y_test = train_test_split(Xall, y, test_size = 0.3)\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [(\"text2number\", TextToNumberClassifier(), slice(4, 4 + 3072))]\n",
    "    , remainder = 'passthrough'\n",
    ")\n",
    "pipe = Pipeline([('preprocess', ct), ('logit', LogisticRegression(penalty = None))])\n",
    "#pipe.fit(Xall_train, y_train).score(Xall_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f1ce8ec-b7ab-4fd3-8297-63bde9e3d23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'preprocess__text2number__base_learner__n_neighbors': 50, 'preprocess__text2number__nx': 1000}\n",
      "Test set score:  0.7469879518072289\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'preprocess__text2number__nx': [50, 200, 1000, 3072],\n",
    "    'preprocess__text2number__base_learner__n_neighbors': [5, 10, 50]  # Access the n_neighbors parameter\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(Xall_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "#rint(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# Test set performance\n",
    "test_score = grid_search.score(Xall_test, y_test)\n",
    "print(\"Test set score: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "084c72c6-3a27-4fa4-bba8-73bb5cd69ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74096386, 0.71686747, 0.75903614, 0.72891566, 0.75301205])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 42)\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5)\n",
    "cross_val_score(grid_search, Xall, y, cv = kf, n_jobs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "584367fd-e30f-43d4-bb17-185693cf7f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74096386, 0.69879518, 0.75903614, 0.73493976, 0.75903614])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, Xall, y, cv = kf, n_jobs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3d96fb-338c-4124-8c84-cd6e78429513",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
